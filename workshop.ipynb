{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d32c4c",
   "metadata": {},
   "source": [
    "Lokesh M\n",
    "212223230114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d2e8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9149b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"income.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb658e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (30000, 10)\n",
      "   age     sex    education  education-num marital-status    workclass  \\\n",
      "0   27    Male      HS-grad              9  Never-married      Private   \n",
      "1   47    Male      Masters             14        Married    Local-gov   \n",
      "2   59    Male      HS-grad              9       Divorced     Self-emp   \n",
      "3   38  Female  Prof-school             15  Never-married  Federal-gov   \n",
      "4   64  Female         11th              7        Widowed      Private   \n",
      "\n",
      "        occupation  hours-per-week income  label  \n",
      "0     Craft-repair              40  <=50K      0  \n",
      "1  Exec-managerial              50   >50K      1  \n",
      "2   Prof-specialty              20  <=50K      0  \n",
      "3   Prof-specialty              57   >50K      1  \n",
      "4  Farming-fishing              40  <=50K      0  \n"
     ]
    }
   ],
   "source": [
    "# Display information\n",
    "print(\"Shape:\", data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e01f4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'income' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ad84876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical: ['sex', 'education', 'marital-status', 'workclass', 'occupation']\n",
      "Continuous: ['age', 'education-num', 'hours-per-week', 'label']\n",
      "Label: income\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_cols.remove(label_col)\n",
    "continuous_cols = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(\"Categorical:\", categorical_cols)\n",
    "print(\"Continuous:\", continuous_cols)\n",
    "print(\"Label:\", label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e71be093",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode label column\n",
    "target_encoder = LabelEncoder()\n",
    "data[label_col] = target_encoder.fit_transform(data[label_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a1bb3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale continuous columns\n",
    "scaler = StandardScaler()\n",
    "data[continuous_cols] = scaler.fit_transform(data[continuous_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85d525df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.iloc[:25000]\n",
    "test_data = data.iloc[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08056ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train = torch.tensor(train_data[categorical_cols].values, dtype=torch.int64)\n",
    "con_train = torch.tensor(train_data[continuous_cols].values, dtype=torch.float)\n",
    "y_train = torch.tensor(train_data[label_col].values, dtype=torch.long)\n",
    "\n",
    "cat_test = torch.tensor(test_data[categorical_cols].values, dtype=torch.int64)\n",
    "con_test = torch.tensor(test_data[continuous_cols].values, dtype=torch.float)\n",
    "y_test = torch.tensor(test_data[label_col].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31c94a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_ds = TensorDataset(cat_train, con_train, y_train)\n",
    "test_ds = TensorDataset(cat_test, con_test, y_test)\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b20d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, hidden_sz=50, dropout=0.4):\n",
    "        super().__init__()\n",
    "        # Embeddings for categorical variables\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(dropout)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        # Layers\n",
    "        self.fc1 = nn.Linear(sum([nf for _, nf in emb_szs]) + n_cont, hidden_sz)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_sz)\n",
    "        self.fc2 = nn.Linear(hidden_sz, out_sz)\n",
    "        self.out = nn.Softmax(dim=1)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        # Embedding categorical data\n",
    "        embeddings = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        # Normalize continuous\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        \n",
    "        # Combine\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.drop(torch.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a02d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_szs = [len(label_encoders[col].classes_) for col in categorical_cols]\n",
    "emb_szs = [(size, min(50, (size + 1) // 2)) for size in cat_szs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "358e19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = TabularModel(emb_szs, len(continuous_cols), 2, hidden_sz=50, dropout=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33fce538",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c17f0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Loss: 0.0000\n",
      "Epoch [100/300], Loss: 0.0000\n",
      "Epoch [150/300], Loss: 0.0000\n",
      "Epoch [200/300], Loss: 0.0000\n",
      "Epoch [250/300], Loss: 0.0000\n",
      "Epoch [300/300], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "epochs = 300\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for cat, con, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(cat, con)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c61d6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.0000\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct, total, test_loss = 0, 0, 0.0\n",
    "with torch.no_grad():\n",
    "    for cat, con, label in test_loader:\n",
    "        outputs = model(cat, con)\n",
    "        loss = criterion(outputs, label)\n",
    "        test_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += (preds == label).sum().item()\n",
    "        total += label.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"\\nTest Loss: {test_loss/len(test_loader):.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnv",
   "language": "python",
   "name": "pytorchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
